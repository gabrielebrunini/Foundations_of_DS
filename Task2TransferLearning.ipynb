{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syYqOr0bX9Do"
   },
   "source": [
    "# Practical 3: Transfer Learning\n",
    "\n",
    "This is the second task of Practical 3. You will use transfer learning to build a convolutional neural network to tackle the CIFAR-10 dataset (https://www.cs.toronto.edu/~kriz/cifar.html). \n",
    "You could select an existing trained model (VGG16 excluded) from Keras (https://keras.io/api/applications/) and fine-tune it to solve the classification problem of CIFAR-10. \n",
    "\n",
    "We will mark your code based on the accuracy of your model. You should try to get **at least 80%** accuracy on this dataset. Don't forget to save and check in your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZzauOzHX9EH"
   },
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F5HDdLmLX9EK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBluUEfsX9ES"
   },
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "In this block, you will prepare the data for the training, such as apply the preprocess function of your selected model and perform data augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E4JqVzF8X9ET",
    "outputId": "e9a79b88-18e3-4d0d-96ef-c354fedb65eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10.load_data()\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sopm1_TeX9Eh",
    "outputId": "2da1520d-940e-4c62-e130-12801787bfce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "# ResNet50 preprocess\n",
    "X_train_full = preprocess_input(X_train_full)\n",
    "X_test = preprocess_input(X_test)\n",
    "X_train_full = X_train_full.astype('float32')\n",
    "\n",
    "y_train_full = keras.utils.to_categorical(y_train_full, num_classes = 10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "print(y_train_full.shape)\n",
    "\n",
    "# get validation dataset\n",
    "np.random.seed(42) # we set the random seed to make sure everytime the data is shuffled in the same way \n",
    "shuffled_indices = np.random.permutation(X_train_full.shape[0])\n",
    "X_valid, X_train = X_train_full[shuffled_indices[:5000]], X_train_full[shuffled_indices[5000:]]\n",
    "y_valid, y_train = y_train_full[shuffled_indices[:5000]], y_train_full[shuffled_indices[5000:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJZ8Qfe3X9Em"
   },
   "source": [
    "For all our tests we will be performing data augmentation (rotation, horizontal flip, zoom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EJppWVPdX9Eq"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=20, horizontal_flip=True, zoom_range=0.1) #, rescale=1./255\n",
    "\n",
    "train_data_generator = datagen.flow(X_train_full, y_train_full, batch_size=200)\n",
    "valid_data_generator = datagen.flow(X_valid, y_valid, batch_size=200)\n",
    "\n",
    "inputs = keras.Input(shape=(32,32,3))\n",
    "upscale = keras.layers.Lambda(lambda x: tf.compat.v1.image.resize(x,(224,224)))(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDtvxzz3X9Ex"
   },
   "source": [
    "## ResNet50\n",
    "![](resnet50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTTTjl5tX9Ey"
   },
   "source": [
    "## ResNet50 - CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RkPIH51X9Ez"
   },
   "source": [
    "We will first evaluate the pretrained on the ImageNet dataset ResNet50 model on the CIFAR-10 dataset. Our classification model requires 10 output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2wSPuKP7rMp",
    "outputId": "e9fa37d7-aa01-4974-aea6-7cec4a5371f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "225/225 [==============================] - 7027s 31s/step - loss: 1.0003 - accuracy: 0.6532 - val_loss: 0.4806 - val_accuracy: 0.8326\n",
      "Epoch 2/3\n",
      "225/225 [==============================] - 6958s 31s/step - loss: 0.4630 - accuracy: 0.8403 - val_loss: 0.4304 - val_accuracy: 0.8486\n",
      "Epoch 3/3\n",
      "225/225 [==============================] - 7093s 32s/step - loss: 0.4096 - accuracy: 0.8571 - val_loss: 0.4145 - val_accuracy: 0.8560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c98e0a6d8>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = keras.applications.ResNet50(include_top=True, \n",
    "                                     input_shape=(224,224,3), \n",
    "                                     weights='imagenet',\n",
    "                                     input_tensor = upscale)\n",
    "x = resnet.layers[-2].output\n",
    "\n",
    "outputs= keras.layers.Dense(units=10, activation='softmax')(x) # output layer with softmax activation\n",
    "model = keras.Model(inputs=resnet.input, outputs=outputs)\n",
    "\n",
    "# we freeze the layers from ResNet50 \n",
    "for layer in resnet.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data_generator, epochs=3, validation_data=(valid_data_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6ZyZ01G7rMq",
    "outputId": "d997b62a-b589-4ff5-9793-b37e7841e9ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1440s 5s/step - loss: 0.3053 - accuracy: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30530694127082825, 0.8945000171661377]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvShkzJuX9FF"
   },
   "source": [
    "We observe that the test accuracy is higher than the training and validation data accuracy. This might be from the selection of instances to fill each set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ubjNJn8X9FH"
   },
   "source": [
    "## Randomised Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vwv5v5-UX9FM"
   },
   "source": [
    "Since our dataset contains many instances we decide to make the final stage 5 of the ResNet50 model trainable. We then run a randomised search to find the best number of layers and neurons to be used for our classifier, which will be added after the convolutional base of the ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MD75eHgJX9FO",
    "outputId": "881f5c98-db91-45d3-f6a6-2f74be9d24aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1042/1042 [==============================] - 2522s 2s/step - loss: 0.4262 - accuracy: 0.8606\n",
      "Epoch 2/3\n",
      "1042/1042 [==============================] - 2642s 3s/step - loss: 0.1996 - accuracy: 0.9327\n",
      "Epoch 3/3\n",
      "1042/1042 [==============================] - 2655s 3s/step - loss: 0.1293 - accuracy: 0.9564\n",
      "521/521 [==============================] - 760s 1s/step - loss: 0.2678 - accuracy: 0.9199\n",
      "Epoch 1/3\n",
      "1042/1042 [==============================] - 2666s 3s/step - loss: 0.4396 - accuracy: 0.8595\n",
      "Epoch 2/3\n",
      "1042/1042 [==============================] - 2590s 2s/step - loss: 0.2156 - accuracy: 0.9286\n",
      "Epoch 3/3\n",
      "1042/1042 [==============================] - 2445s 2s/step - loss: 0.1328 - accuracy: 0.9543\n",
      "521/521 [==============================] - 728s 1s/step - loss: 0.3200 - accuracy: 0.9125\n",
      "Epoch 1/3\n",
      "1042/1042 [==============================] - 2491s 2s/step - loss: 0.4262 - accuracy: 0.8610\n",
      "Epoch 2/3\n",
      "1042/1042 [==============================] - 2507s 2s/step - loss: 0.2061 - accuracy: 0.9316\n",
      "Epoch 3/3\n",
      "1042/1042 [==============================] - 2539s 2s/step - loss: 0.1282 - accuracy: 0.9556\n",
      "521/521 [==============================] - 755s 1s/step - loss: 0.2826 - accuracy: 0.9153\n",
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 3846s 2s/step - loss: 0.3871 - accuracy: 0.8756\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4111s 3s/step - loss: 0.1832 - accuracy: 0.9376\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4122s 3s/step - loss: 0.1221 - accuracy: 0.9588\n",
      "{'n_neurons': 128, 'n_hidden': 2}\n",
      "0.9158999721209208\n"
     ]
    }
   ],
   "source": [
    "def build_model(n_hidden=1, lr=0.001, n_neurons=30, dr=0.2, freeze=-33):\n",
    "    resnet = keras.applications.ResNet50(include_top=False, \n",
    "                                     input_shape=(224,224,3),    \n",
    "                                     weights='imagenet',\n",
    "                                     input_tensor = upscale)\n",
    "    x = resnet.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    for layer in range(n_hidden):\n",
    "        x = keras.layers.Dense(n_neurons)(x)\n",
    "        \n",
    "    outputs= keras.layers.Dense(units=10, activation='softmax')(x) # output layer with softmax activation\n",
    "    model = keras.Model(inputs=resnet.input, outputs=outputs)\n",
    "\n",
    "      # freeze the layers from ResNet50 \n",
    "    for layer in resnet.layers[:freeze]:\n",
    "        layer.trainable=False\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=lr), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "param_distributions = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": [128,256,512,1024],\n",
    "}\n",
    "\n",
    "keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(\n",
    "                        estimator=keras_class, \n",
    "                        param_distributions=param_distributions, \n",
    "                        n_iter=1, \n",
    "                        cv=3)\n",
    "rnd_search_cv.fit(X_train_full, y_train_full, epochs=3)\n",
    "\n",
    "model = rnd_search_cv.best_estimator_.model\n",
    "\n",
    "print(rnd_search_cv.best_params_)\n",
    "print(rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZZ9lRdlX9FQ"
   },
   "source": [
    "## Train the model - Trainable Stage 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zq8BrJ5SX9FS"
   },
   "source": [
    "We will now run the same model in order to test for overfitting and evaluate it's performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6fFTIlnX9FZ",
    "outputId": "98fc700e-45de-4d38-ccfe-f988ee3fff15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 4094s 16s/step - loss: 0.4663 - accuracy: 0.8507 - val_loss: 0.3068 - val_accuracy: 0.8952\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 3828s 15s/step - loss: 0.2487 - accuracy: 0.9132 - val_loss: 0.1873 - val_accuracy: 0.9350\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 3786s 15s/step - loss: 0.1944 - accuracy: 0.9319 - val_loss: 0.2040 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1441bb79580>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = keras.applications.ResNet50(include_top=False, \n",
    "                                     input_shape=(224,224,3), \n",
    "                                     weights='imagenet',\n",
    "                                     input_tensor = upscale)\n",
    "x = resnet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(128)(x)\n",
    "x = keras.layers.Dense(128)(x)\n",
    "        \n",
    "outputs= keras.layers.Dense(units=10, activation='softmax')(x) # output layer with softmax activation\n",
    "model = keras.Model(inputs=resnet.input, outputs=outputs)\n",
    "\n",
    "      # freeze the layers from ResNet50 \n",
    "for layer in resnet.layers[:-33]:\n",
    "    layer.trainable=False\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data_generator, epochs=3, validation_data=(valid_data_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XUCnAWVX9Fc",
    "outputId": "f2a24e3d-a55b-41a0-cfd5-1fd08b07bb8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 439s 1s/step - loss: 0.2679 - accuracy: 0.9203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2678517699241638, 0.9203000068664551]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K60Sv8PPX9Ff"
   },
   "source": [
    "## Train the model - Trainable Stages 4 & 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12NDV1C2X9Fg"
   },
   "source": [
    "We evaluate our model when we increase the number of trainable weights by not reusing stages 4 and 5 of the ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mtBqZaiX9Fi",
    "outputId": "af364f14-97f7-468a-b18b-86d563c763be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 7569s 30s/step - loss: 0.5594 - accuracy: 0.8181 - val_loss: 0.5029 - val_accuracy: 0.8252\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 7921s 32s/step - loss: 0.3113 - accuracy: 0.8926 - val_loss: 0.3514 - val_accuracy: 0.8752\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 8214s 33s/step - loss: 0.2493 - accuracy: 0.9132 - val_loss: 0.3391 - val_accuracy: 0.8852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23aa8bfdb20>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = keras.applications.ResNet50(include_top=False, \n",
    "                                     input_shape=(224,224,3), \n",
    "                                     weights='imagenet',\n",
    "                                     input_tensor = upscale)\n",
    "x = resnet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(128)(x)\n",
    "x = keras.layers.Dense(128)(x)\n",
    "        \n",
    "outputs= keras.layers.Dense(units=10, activation='softmax')(x) # output layer with softmax activation\n",
    "model = keras.Model(inputs=resnet.input, outputs=outputs)\n",
    "\n",
    "# freeze the layers from ResNet50 \n",
    "for layer in resnet.layers[:-95]:\n",
    "    layer.trainable=False\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data_generator, epochs=3, validation_data=(valid_data_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVn2YMYVX9Fk",
    "outputId": "1e215913-2d59-411c-8c0e-42d4e8dfd582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 453s 1s/step - loss: 0.4495 - accuracy: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4495455026626587, 0.8633000254631042]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCADlZdQX9Fl"
   },
   "source": [
    "We will now search for the Dropout method parameter on the \"Trainable Stage 5\" model and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 1446s 2s/step - loss: 0.6568 - accuracy: 0.8147\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1437s 2s/step - loss: 0.2852 - accuracy: 0.9090\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1423s 2s/step - loss: 0.1895 - accuracy: 0.9410\n",
      "782/782 [==============================] - 842s 1s/step - loss: 0.3010 - accuracy: 0.9131\n",
      "Epoch 1/3\n",
      "782/782 [==============================] - 1395s 2s/step - loss: 0.6835 - accuracy: 0.8106\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1422s 2s/step - loss: 0.2918 - accuracy: 0.9048\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1400s 2s/step - loss: 0.1910 - accuracy: 0.9395\n",
      "782/782 [==============================] - 872s 1s/step - loss: 0.3917 - accuracy: 0.8854\n",
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 2861s 2s/step - loss: 0.5317 - accuracy: 0.8465\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 2825s 2s/step - loss: 0.2338 - accuracy: 0.9239\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 2868s 2s/step - loss: 0.1687 - accuracy: 0.9461\n",
      "{'dr': 0.4000000000000001}\n",
      "0.8992599844932556\n"
     ]
    }
   ],
   "source": [
    "def build_model(dr, freeze=-33):\n",
    "    resnet = keras.applications.ResNet50(include_top=False, \n",
    "                                     input_shape=(224,224,3), \n",
    "                                     weights='imagenet',\n",
    "                                     input_tensor = upscale)\n",
    "    x = resnet.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dense(128)(x)\n",
    "    x = keras.layers.Dropout(dr)(x)\n",
    "    x = keras.layers.Dense(128)(x)\n",
    "    x = keras.layers.Dropout(dr)(x)\n",
    "        \n",
    "    outputs= keras.layers.Dense(units=10, activation='softmax')(x) # output layer with softmax activation\n",
    "    model = keras.Model(inputs=resnet.input, outputs=outputs)\n",
    "\n",
    "      # freeze the layers from ResNet50 \n",
    "    for layer in resnet.layers[:freeze]:\n",
    "        layer.trainable=False\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "param_distributions = {\n",
    "    \"dr\": np.arange(0.2, 0.5, 0.1).tolist(),\n",
    "}\n",
    "\n",
    "keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(\n",
    "                        estimator=keras_class, \n",
    "                        param_distributions=param_distributions, \n",
    "                        n_iter=1, \n",
    "                        cv=2)\n",
    "rnd_search_cv.fit(X_train_full, y_train_full, epochs=3)\n",
    "\n",
    "model = rnd_search_cv.best_estimator_.model\n",
    "\n",
    "print(rnd_search_cv.best_params_)\n",
    "print(rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 358s 1s/step - loss: 0.2913 - accuracy: 0.9148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2913144826889038, 0.9147999882698059]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that with dropout the model is less accurate by 0.55%. Therefore for the classification of the CIFAR-10 dataset when training for 3 epochs, our most accurate model is the \"Trainable Stage 5\" Resnet50 model with accuracy 92.03%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now evaluate that model with 5 epochs since we believe by increasing the number of epochs the accuracy will improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 3173s 13s/step - loss: 0.4549 - accuracy: 0.8517 - val_loss: 0.3902 - val_accuracy: 0.8676\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 3206s 13s/step - loss: 0.2451 - accuracy: 0.9148 - val_loss: 0.1884 - val_accuracy: 0.9344\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 3203s 13s/step - loss: 0.1885 - accuracy: 0.9327 - val_loss: 0.1730 - val_accuracy: 0.9386\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 3211s 13s/step - loss: 0.1597 - accuracy: 0.9443 - val_loss: 0.1317 - val_accuracy: 0.9540\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 3192s 13s/step - loss: 0.1339 - accuracy: 0.9527 - val_loss: 0.1168 - val_accuracy: 0.9582\n"
     ]
    }
   ],
   "source": [
    "resnet = keras.applications.ResNet50(include_top=False, \n",
    "                                     input_shape=(224,224,3), \n",
    "                                     weights='imagenet',\n",
    "                                     input_tensor = upscale)\n",
    "x = resnet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(128)(x)\n",
    "x = keras.layers.Dense(128)(x)\n",
    "        \n",
    "outputs= keras.layers.Dense(units=10, activation='softmax')(x) # output layer with softmax activation\n",
    "model5 = keras.Model(inputs=resnet.input, outputs=outputs)\n",
    "\n",
    "# freeze the layers from ResNet50 \n",
    "for layer in resnet.layers[:-33]:\n",
    "    layer.trainable=False\n",
    "\n",
    "model5.compile(optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model5.fit(train_data_generator, epochs=5, validation_data=(valid_data_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 364s 1s/step - loss: 0.2380 - accuracy: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23795033991336823, 0.9323999881744385]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4YdAb89cX9Fn"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assume you have stored the training history in the variable \"history\"\n",
    "# Show the learning curves\n",
    "pd.DataFrame(history.history).plot(figsize=(12, 8))\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfQmfn2vX9Fn"
   },
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aHNue8nZX9Fo"
   },
   "outputs": [],
   "source": [
    "model5.save('cifar10.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtJ42My5X9Fo"
   },
   "source": [
    "## Load the model and evaluate it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lIMn8LuzX9Fq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 336s 1s/step - loss: 0.2380 - accuracy: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23795033991336823, 0.9323999881744385]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"cifar10.h5\")\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YE6PNwgnX9Fr"
   },
   "source": [
    "## Short report\n",
    "\n",
    "Please write briefly how you build and train the model. Please include the decisions you made, such as how you decide the number of layers reused from the selected model, and the difficulties you met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Coss4SeFX9Fr"
   },
   "source": [
    "We used transfer learning to build a convolutional Neural Network to tackle the CIFAR-10 dataset by using the ResNet50 model, which is a very good option for our problem setting; ResNet50 (reference: https://arxiv.org/abs/1512.03385) has been created to tackle the classification problem of the ImageNet dataset, which contains data similar to CIFAR-10. Its main advantage is that it solves the vanishing gradient problem by using skip connections leading to addition, thus forming residual blocks. The gradients can flow directly through the skip connections backwards from later layers to initial filters. This also allows the creation of deeper NNs (and CNNs). Considering training time, ResNet50 is a good option since it has a relatively low number of parameters (26M) and TFLOPs. <br>\n",
    "The network inputs are 32x32 images, which have been pre-processed to obtain the right formatting for the ResNet50 model (224x224).\n",
    "The target variable has been categorized in 10 classes, given that the CIFAR-10 dataset consists of 50k training images and 10k testing images belonging to 10 classes. <br>\n",
    "\n",
    "Our **baseline attempt** was to evaluate the performance of ResNet50 on the CIFAR-10 dataset. We replaced the output layer from 1000 classifications pretrained for imagenet to 10 classifications. We freeze all layers of ResNet50. The test accuracy achieved on the CIFAR-10 dataset is 89.45% after 3 epochs (and higher than validation accuracy by about 4%, possible due to the selected splitting of the data). <br>\n",
    "\n",
    "Since CIFAR-10 contains a large enough training dataset, we decided to re-train the upper layer (stage 5) of the ResNet50 model (see image above) that calculates more specific features of the ImageNet dataset. <br>\n",
    "To form our classifier we performed a **randomised search** to find the right amount of dense layers and neurons. As a result, the search provided us with a 3-layer NN, 128 HU. <br>\n",
    "\n",
    "Since ResNet50 tackles the problem of the vanishing gradient, we expect to not encounter this problem when we have only a few hidden layers in our classifier. As a result we don't expect to encounter difficulties when applying either the ReLU or the linear activation function to our hidden layers. An initial training with the ReLU activation function and a 2-layer, 1024 HU classifier produced an accuracy of 89%. Eventually, with the 3-layer NN, 128 HU classifier we obtained higher accuracy by using the linear activation function.<br>\n",
    "\n",
    "We also wanted to test our classifier in the model by re-training both stage 4 & 5 of ResNet50. After 3 epochs, the \"trainable Stage 5 ResNet50\" model outperforms it by 5.7% on the test dataset. As a result, we proceeded by fine-tuning the latter model, which we also tested for 5 epochs with 1.21% accuracy increase. The accuracies obtained by the models are presented in the Table below.\n",
    "\n",
    "For both model structures, we applied some <u>techniques</u> to tackle the most-frequently-encountered NN problems, such as overfitting, training time and a problem that is more specifically-related to transfer learning: image rescaling.\n",
    "\n",
    "- To account for the overfitting issue, we used **data augmentation** on both architectures; specifically, we used a rotation range of 20, horizontal flip and a zoom range of 0.1. \n",
    "\n",
    "- **Image resizing** is a required preprocessing step in transfer learning, to tackle the fact that CIFAR-10 has 32x32-sized images, while ResNet50 was trained using 224x224-sized ones. Thus, we need to upscale our training images if we want to re-use the model's optimal weights. We did so by adding a lambda layer at the top of the convolutional base, where the same aspect ratio of each image has been kept to avoid distortions. This preprocessing step allowed us to achieve a higher classification accuracy for all tested models.\n",
    "\n",
    "- To optimize the model's weights, we opted for the **Adam** optimizer, an efficient optimization technique that normally converges faster. We setted a learning rate parameter of 0.001.\n",
    "\n",
    "- To increase the performance of the \"trainable Stage 5 ResNet50\" model we also tested the **dropout** technique, where randomly some neurons are temporarily ignored during a training step, but may be active in another one; the dropout rate has been fine-tuned to reach the highest performance in our model, and it was set to 0.4. This led to accuracy 91.48%, showing a decrease of 0.55% when compared to the original model.\n",
    "\n",
    "The results we obtained by evaluating the three models on the CIFAR-10 dataset are presented in the Table below:\n",
    "\n",
    "Model Description | Classifier | Preprocessing | Test accuracy (%) |\n",
    "--- | --- | --- | --- \n",
    "Basic ResNet50 | ResNet50 AvgPooling output<br>1-layer | preprocessing, image resizing, data augmentation,<br>output categorized (10 classes) | 89.45 |\n",
    "trainable Stage 5 ResNet50 (3-epochs)| ResNet50 Stage 4 output<br>3-layer NN, 128 HU | preprocessing, image resizing, data augmentation,<br>output categorized (10 classes) |  92.03 | \n",
    "trainable Stage 5 ResNet50 (5-epochs)| ResNet50 Stage 4 output<br>3-layer NN, 128 HU | preprocessing, image resizing, data augmentation,<br>output categorized (10 classes) |  93.24 |\n",
    "trainable Stages 4 & 5 ResNet50| ResNet50 Stage 3 output<br>3-layer NN, 128 HU| preprocessing, image resizing, data augmentation,<br>output categorized (10 classes) | 86.33 | <br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Final File_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
